from abc import ABC, abstractmethod
from pathlib import Path
from typing import List, Optional

from pydantic import AwareDatetime, BaseModel, Field
from ragathon.utils.date import utcnow


class RetrievedChunk(BaseModel):
    """Represents a chunk of text retrieved by the RAG pipeline."""

    chunk_id: str = Field(..., description="The unique identifier of the chunk")
    section_id: Optional[str] = Field(
        None, description="The section in the source document, if applicable"
    )
    document_id: Optional[str] = Field(
        None, description="The identifier of the source document, if applicable"
    )
    text: str = Field(..., description="The retrieved text chunk")
    rank: int = Field(
        ..., description="The rank of this chunk in the retrieval results"
    )
    score: float = Field(..., description="The relevance score of this chunk")


class QueryInfo(BaseModel):
    """Contains information about the query processing."""

    original_query: str = Field(
        ..., description="The original query provided by the user"
    )
    processed_query: Optional[str] = Field(
        None, description="The query after any preprocessing or reformulation"
    )
    query_embedding: Optional[List[float]] = Field(
        None, description="The vector embedding of the query, if used"
    )


class RetrievalMetrics(BaseModel):
    """Metrics related to the retrieval process."""

    retrieval_method: str = Field(
        ...,
        description="The method used for retrieval (e.g., 'BM25', 'dense', 'hybrid')",
    )
    max_retrieve_docs: int = Field(
        ..., description="The maximum number of documents to retrieve"
    )
    total_chunks_retrieved: int = Field(
        ..., description="The total number of chunks actually retrieved"
    )
    retrieval_time_ms: int = Field(
        ..., description="The time taken for retrieval in milliseconds"
    )


class GenerationMetrics(BaseModel):
    """Metrics related to the answer generation process."""

    llm_name: str = Field(..., description="The name of the language model used ")

    input_token_count: int = Field(
        ..., description="The number of tokens in the input question"
    )
    output_token_count: int = Field(
        ..., description="The number of tokens in the generated answer"
    )
    generation_time_ms: int = Field(
        ..., description="The time taken for generation in milliseconds"
    )


class RAGPipelineConfig(BaseModel):
    version: str = Field(..., description="Version of the RAG pipeline.")

    chunking_method: str = Field(..., description="The method to use for chunking.")

    max_chunk_size: int = Field(..., description="The maximum size of each chunk.")

    chunk_overlap: int = Field(
        ...,
        description="The number of overlapping tokens between chunks. Only used for some chunking methods.",
    )

    retrieval_method: str = Field(
        ...,
        description="The method used for retrieval (e.g., 'BM25', 'dense', 'hybrid')",
    )

    generation_model_name: str = Field(
        ..., description="The name of the language model used "
    )

    def get_dir(self, parent_dir: Path) -> Path:
        name = f"{self.chunking_method}-{self.max_chunk_size}-overlap-{self.chunk_overlap}-retriever-{self.retrieval_method}-generator-{self.generation_model_name}"
        return parent_dir / f"{name}-v{self.version}"


class RAGPipelineOutput(BaseModel):
    """
    Represents the complete output of a Retrieval Augmented Generation (RAG) pipeline.
    This includes the input, retrieved information, generated output, and various metrics.
    """

    config: RAGPipelineConfig = Field(
        ..., description="Configuration of the RAG pipeline."
    )

    query_info: QueryInfo = Field(..., description="Information about query processing")
    retrieved_chunks: List[RetrievedChunk] = Field(
        ..., description="List of retrieved text chunks with metadata"
    )
    generated_answer: str = Field(
        ..., description="The answer generated by the language model"
    )
    retrieval_metrics: RetrievalMetrics = Field(
        ..., description="Metrics related to the retrieval process"
    )
    generation_metrics: GenerationMetrics = Field(
        ..., description="Metrics related to the answer generation process"
    )
    started_at: AwareDatetime = Field(
        default_factory=utcnow,
        description="Timestamp of when the pipeline was executed",
    )
    completed_at: Optional[AwareDatetime] = Field(
        ...,
        description="Timestamp of when the pipeline completed",
    )


class RAGPipeline(ABC):
    """The base class for a Retrieval Augmented Generation (RAG) pipeline."""

    @abstractmethod
    async def build_or_load(self) -> None:
        """Build or load any necessary resources for the pipeline."""
        raise NotImplementedError

    @abstractmethod
    async def run(self, query: str, max_retrieved_docs: int) -> RAGPipelineOutput:
        """Run the pipeline with the given query.

        Args:
            query: The input query for the pipeline.
            max_retrieved_docs: The maximum number of documents to retrieve.

        Returns:
            The output of the pipeline.
        """
        raise NotImplementedError
